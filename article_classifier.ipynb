{"cells":[{"cell_type":"markdown","metadata":{"id":"3VCuTicvM07-"},"source":["# __Classification of articles based on the applied research methodology__"]},{"cell_type":"markdown","source":["This notebook was created with the aim of supporting the methodological classification of scientific articles. By using it, the individual articles of the input article set are classified into two groups: **articles using qualitative research methodology** and **articles using quantitative research methodology**.\n","The notebook is divided into 3 main chapters, which are as follows:\n","\n","- **Basic settings**: Installation of the necessary packages and completion of the required basic settings for running.\n","- **Preprocessing of articles for classification**: Preparation of scientific articles for the classification model.\n","- **Classification of articles**: Classification of articles using XGBoost model.\n","\n","To run the notebook, copy the articles to be classified into the *./articles* folder. The articles should be separate PDF files. After running the codes in the notebook, the classification result of the articles will be available in the *./output/article_classification_result.csv* file.\n","\n","\n"],"metadata":{"id":"dg7X-arMAs9c"}},{"cell_type":"markdown","source":["When using the notebook, please cite the scientific article describing the methodology:\n","\n","*Zsolt T. Kosztyán, Tünde Király, Tibor Csizmadia, Attila I. Katona,\n","Ágnes Vathy-Fogarassy. Automated Research Methodology Classification Using Machine Learning. Journal, Vol. p.*"],"metadata":{"id":"5hTeqRba7b4Q"}},{"cell_type":"markdown","source":["### __1. Basic settings__"],"metadata":{"id":"HPIcFtm4GilA"}},{"cell_type":"markdown","source":["Mount your Google Drive to the /content/drive directory in a Google Colab environment:"],"metadata":{"id":"7hRx4WoqH3ci"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoYHK6EwMO4E","collapsed":true},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Install the packages required:"],"metadata":{"id":"Ctk76wn-HLwp"}},{"cell_type":"code","source":["!pip install pdfplumber\n","!pip install tika\n","!pip install fitz\n","!pip install frontend\n","!pip install sympy\n","!pip install xgboost\n","!pip install pymupdf\n","!pip install openpyxl\n","!pip install nltk\n","import nltk\n","nltk.download('wordnet')"],"metadata":{"collapsed":true,"id":"8yfEbrMqQ1DP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the working directory and paths:"],"metadata":{"id":"M6YxS8bVI34y"}},{"cell_type":"code","source":["import os\n","\n","#working directory\n","os.chdir('/content/drive/set/your/working/directory/here/') #set the working directory\n","\n","articlesPath = './articles'\n","outputFolder   = './output'\n","termsFile = './sources/terms.xlsx'"],"metadata":{"id":"x7iKxCvfYYnH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### __2. Preprocessing of articles for classification__"],"metadata":{"id":"OeMUpmgD425f"}},{"cell_type":"markdown","source":["Import the required packages:"],"metadata":{"id":"7duk8y-HQ--k"}},{"cell_type":"code","source":["import sys\n","\n","# Add 'lib' directory to the system path\n","sys.path.append(os.path.abspath('lib'))\n","\n","# Import the necessary classes\n","from logger.logger import Logger\n","from cache_handler.cache_creator import CacheCreator\n","from matrix_generator.matrix_generator import MatrixGenerator"],"metadata":{"id":"kI6-fyveXUwr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate the document-term matrix, the input file for the classification model:"],"metadata":{"id":"8poyhz2sBGE3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzZORdqiOldH"},"outputs":[],"source":["# Functions\n","def generate_cache_file():\n","    global cache_file\n","\n","    c = CacheCreator(\n","            articles_location = articlesPath\n","    )\n","    c.start_generating()\n","    cache_file = '_article_cache.pkl'\n","\n","def generate_document_term_matrix():\n","    m = MatrixGenerator(\n","        cache_file = cache_file,\n","        output_folder = outputFolder,\n","        words_file = termsFile,\n","        lemmatize = True,\n","        cutted = False,\n","        types_csv = '',\n","        generate_model = False,\n","        binarize = True\n","    )\n","\n","    m.generate_matrix()\n","\n","\n","# Generate the document-term matrix\n","cache_file = ''\n","generate_cache_file()\n","generate_document_term_matrix()"]},{"cell_type":"markdown","source":["### __3. Classification of articles__"],"metadata":{"id":"osEFssIZj5SR"}},{"cell_type":"markdown","source":["Classify the articles using the classification model developed:"],"metadata":{"id":"mNMW2WilBlOg"}},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","import xgboost as xgb\n","\n","# Import document-term matrix from csv file\n","df = pd.read_csv(outputFolder + '/document_term_matrix.csv')\n","\n","# Import the classification model\n","with open('./model/XGB_model.pkl', 'rb') as f:\n","  model = pickle.load(f)\n","\n","# Set the input variables and run the model\n","X = df[df.columns[1:]]\n","y_pred = model.predict(X)\n","\n","# Save the results into a dataframe and recode it\n","df_pred = pd.DataFrame(y_pred, columns=['predicted_class'])\n","result = pd.concat([df, df_pred], axis=1)\n","result = result[['title', 'predicted_class']]\n","result['predicted_class'].replace(0, 'quantitative', inplace=True)\n","result['predicted_class'].replace(1, 'qualitative', inplace=True)\n","\n","# Count the articles in the classes\n","counts = result['predicted_class'].value_counts()\n","quantitative_count = counts.get('quantitative', 0)\n","qualitative_count = counts.get('qualitative', 0)\n","\n","# Save the result into a csv file\n","result.to_csv(outputFolder + '/article_classification_result.csv', index=False)\n","\n","# Print results\n","print('\\nNumber of articles classified: ', df.shape[0])\n","print('\\nNumber of articles based on quantitative research: ', quantitative_count)\n","print('Number of articles based on qualitative research: ', qualitative_count)\n","print('\\nThe detailed results have been saved in the article_classification_result.csv file in the output folder.')"],"metadata":{"id":"9MwR6J_-aFxA"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}